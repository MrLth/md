# 超文本传输协议

**Hyper Text Transfer Protocal**

# HTTP 0.9

​	诞生于 1991 年，主要用于学术交流，它的实现很简单，采用基于请求响应的模式，从客户端发出请求，服务器返回数据

## 1. 请求流程

	1. **TCP 三次握手**：HTTP 是基于 TCP 协议的，所以客户端先要根据 IP 地址、端口号和服务器建立 TCP 连接。
 	2. **请求**：发送一个 **GET** 请求行的信息，如 **GET /index.html** 用来获取 index.html
 	3. **响应**：服务器接收到请求后，读取对应的 HTML 文件，并将数据以 ASCII 字符流返回给客户端
 	4.  **TCP 四次挥手**：HTML 文档接收完毕后，断开连接

<img src="https://static001.geekbang.org/resource/image/db/34/db1166c68c22a45c9858e88a234f1a34.png" style="zoom:50%;" />

## 2. 特点

1. 只有请求行，没有 **请求头** 和 **请求体**，只需要一个请求行就足够表达诉求了
2. 没有 **响应头**，服务器并不需要告诉客户端太多信息，只需要返回数据就行了
3. 文件内容以 **ASCII** 字符流进行传输，毕竟只是 HTML 文件

# HTTP 1.0

​	1994年出现了拨号上网，网景又推出了一款浏览器，从此万维网就不再局限于学术交流了，而是进入了高速发展，随之而来的万维网联盟（W3C）和 HTTP工作组（HTTP-WG）的创建，他们致力于 HTML 的发展和 HTTP 的改进。

​	在浏览器中展示的不单是 HTML 文件了，还包括了 JavaScript、CSS、图片、音频、视频等不同类型的文件。因此支持多种类型的文件下载是 HTTP/1.0 的一个核心诉求，而且文件格式不仅仅局限于 ASCII 编码，还有很多其他类型编码的文件。

## 改进

1. 引入 **请求头** 和 **响应头**，它们都是以 `key-value` 的形式保存的，使 HTTP 支持传输多种不同类型的类型，为了实现这一目的，浏览器会在请求时在请求头加上以下数据，告诉服务器它期待返回什么样的文件

   1. 文件类型

   2. 文件的压缩的方法

   3. 文件的编码方式

   4. 指定语言（国际化支持）

      ```http
      GET /index.html HTTP/1.0
      accept: text/html
      accept-encoding: gzip, deflate, br
      accept-Charset: ISO-8859-1,utf-8
      accept-language: zh-CN,zh
      ```

      ```http
      HTTP/1.0 200 OK
      content-encoding: br
      content-type: text/html; charset=UTF-8
      ```

      > 服务器会根据 **请求头** 返回浏览器需要的文件，但是部分要求无法满足也是没有办法的，比如不支持 gzip 压缩，最终以 br 进行压缩返回
      >
      > 最终服务器会在 **响应头** 标明使用的压缩方式、文件类型及编码方式

2. 引入 **状态码**，有的请求服务器无法处理，或者处理出错 ，服务器就会通过将状态码存储在响应行告知浏览器。

3. 引入 **Cache 机制**，减轻服务器的压力，用于缓存已经下载过的数据

4. 加入 **user-Agent** 字段，帮助服务器了解客户端的基本信息

<img src="https://static001.geekbang.org/resource/image/b5/7d/b52b0d1a26ff2b8607c08e5c50ae687d.png" style="zoom:50%;" />

# HTTP 1.1 

​	随着技术的发展，HTTP 1.0 也不够用了，就出现了 HTTP 1.1

## 改进

1. **keep alive**，持久连接。
           HTTP 1.0 每次通信都要经过建立TCP连接、传输HTTP数据然后断开TCP连接三个阶段。随着网页内容的丰富，各种资源越来越多，这样会造成大量的性能和资源的浪费。
           HTTP 1.1 增加了持久连接，它的特点是在一个 TCP 连接上可以传输多个 HTTP 请求，只要浏览器和服务器没有明断断开连接，那么 TCP 连接会一直保持。
   - **持久连接默认开启**
   - **同一域名下，浏览器最多允许同时建立 6 个 TCP 持久连接**

> 使用 CDN 域名分片 机制，为每个域名都维护 6 个连接，这样就可以大大减轻整个资源的下载时间

1. 不成熟的 HTTP 管线化
           这是为了解决 **队头阻塞** 的问题，HTTP1.1 尝试通过管线化的技术来解决队头阻塞的问题（将多个 HTTP 请求整批提交给服务器，虽然可以整批发送请求，不过服务器依然需要根据请求顺序来回复浏览器的请求）
   ~~最后各浏览器都放弃了管线化技术~~
2. **请求头中增加了 Host 字段**，提供对虚拟主机的支持
           在 HTTP/1.0 中，每个域名绑定了一个唯一的 IP 地址，因此一个服务器只能支持一个域名。但是随着虚拟主机技术的发展，需要实现在一台物理主机上绑定多个虚拟主机，每个虚拟主机都有自己的单独的域名，这些单独的域名都公用同一个 IP 地址。
   因此，HTTP/1.1 的请求头中增加了 Host 字段**，用来表示当前的域名地址，这样服务器就可以根据不同的 Host 值做不同的处理。
3. 引入 **Chunk transfer** 机制，对动态生成的内容提供了完美支持
          在设计 HTTP 1.0 时，服务器需要在响应头设置完整的数据大小，如 **Content-lengh:901**，这样浏览器就可以根据设置的大小来接收数据。不过随着服务器端的技术发展，很多页面的内容都是动态生成的，因此在传输数据之前并不知道最终的数据的大小，这就导致了浏览器不知道何时会接收完所有的文件数据。
           在 Chunk transfer 机制中，服务器将数据分割成若干任意大小的数据块，每个数据块发送时都会附上上个数据块的长度，最后使用一个零长度的块作为发送数据完成的标志。
4. 客户端 Cookie、安全机制

## 未解决的问题

1. 队头阻塞问题
2. 文本传输效率问题，而且不安全
3. header 中每次都传输类似头，增加了传输成本

# HTTP 2

## 1. HTTP 1.1 的主要问题

1. 对带宽的利用率不理想，造成这个的主要原因有
   1. **TCP 的慢启动**，当一个TCP连接建立后，就进入数据发送状态，刚开始 TCP 协议会采用一个非常慢的速度去发送数据，然后慢慢加快发送数据的速度，直到发送数据的速度达到一个理想的状态。这一机制的目的是为了减少网络拥塞，无法改变。
      对于网页来说，页面的关键资源并不大，而通常这些文件都是在 TCP 建立好后就要发送请求的，TCP 的慢启动会拉长页面的渲染时间
   2. **没有优先级**，同时请求的**多条 TCP 连接会竞争带宽**
      带宽充足时，每条连接发送和接收的速度会慢慢上升。
      带宽不足时，这些 TCP 连接又会减慢发送和接收的速度。
      我们需要的关键资源应该需要更高的优先级，更快完成传输！
   3. **队头阻塞**
      在 HTTP/1.1 中使用持久连接时，虽然能公用一个 TCP 管道，但是在一个管道中同一时刻只能处理一个请求，在当前的请求没有结束之前，其他的请求只能处于阻塞状态。这意味着我们不能随意在一个管道中发送请求和接收内容。这是一个很严重的问题，因为阻塞请求的因素有很多，并且都是一些不确定性的因素，假如有的请求被阻塞了 5 秒，那么后续排队的请求都要延迟等待 5 秒，在这个等待的过程中，带宽、CPU 都被白白浪费了。

## 2. HTTP 2 的多路复用

​	慢启动和 TCP 连接之间相互竞争带宽是由于 TCP 本身的机制导致的，而队头阻塞是由于 HTTP 1.1 的机制导致的。

​	HTTP 2 的解决方案是：**一个域名只使用一个 TCP 长连接**

- **维护一个队列，有请求时就加入队列**
- **每个请求都有一个 ID ，浏览器和服务器会根据 ID 发送和接收对应的数据，最后拼接成一个完整的文件，使数据可以随意发送**
- **队列并非先进先出结构，服务器根据资源的优先级决定优先返回哪个资源 **

​	<img src="https://static001.geekbang.org/resource/image/0a/00/0a990f86ad9c19fd7d7620b2ef7ee900.jpg" style="zoom:50%;" />

### 具体实现

​	HTTP 2 新增了一个**二进制分帧层**，以下为一个 HTTP 2 的请求和接收过程

1. 浏览器准备好请求行、请求头等信息（POST 还会有请求体）
2. 这些数据经过二进制分帧层后，会被转换为一个个带有 **请求ID** 编号的帧，然后通过协议栈将这些帧发送给服务器
3. 服务器接收到所有帧后，将相同 **请求ID** 的帧合并为一条完整的请求信息
4. 然后服务器处理该条请求，并将处理的响应行、响应头、响应体分别发送至二进制分帧层
5. 同样，二进制分帧层会将这些数据转换为一个个带个 **请求ID** 的帧，浏览器最后完全拼接交给对应的请求

<img src="https://static001.geekbang.org/resource/image/86/6a/86cdf01a3af7f4f755d28917e58aae6a.png" style="zoom:25%;" />

## 3. HTTP 2 其它的特性

​	得益于一个域名只有一个 TCP 连接，HTTP 2 还可以做到以下事：

1. 可以设置请求的优先级
2. 服务器推送
   除了设置请求的优先级外，HTTP/2 还可以直接将数据提前推送到浏览器。你可以想象这样一个场景，当用户请求一个 HTML 页面之后，服务器知道该 HTML 页面会引用几个重要的 JavaScript 文件和 CSS 文件，那么在接收到 HTML 请求之后，附带将要使用的 CSS 文件和 JavaScript 文件一并发送给浏览器，这样当浏览器解析完 HTML 文件之后，就能直接拿到需要的 CSS 文件和 JavaScript 文件，这对首次打开页面的速度起到了至关重要的作用。
3. 头部压缩

# HTTP 3

## 1. HTTP 2 未解决的TCP 的队头阻塞

​	TCP 为了保证双向稳定可靠的传输，会对每个数据包都有编号，分为1、2、3、... 。每次 TCP 都会发送若干个包，并且每个包都需要在规定的超时重传时间内收到客户端发送的 “确认接收” 包，否则服务器就会再发送一次丢失的包。在这一重传过程中服务器不会继续发送之后的数据，直到这一批包都收到确认。

> 由于 HTTP 2 只有一条 TCP 连接，一旦发生队头阻塞，影响会比 HTTP 1.1 更大，测试数据表明，当丢包率达到 2%， HTTP 2 的性能还不如 HTTP 1.1

## 2. TCP 建立时的延时

### **RTT (Roud Trip Time)**

​	我们把从浏览器发送一个数据包到服务器，再从服务器返回一个数据包到浏览器的整个往返时间称为RTT，RTT是反映网络性能的一个重要指标

<img src="https://static001.geekbang.org/resource/image/e9/4f/e98927e19b20349815fb8f499067cb4f.png" style="zoom:25%;" />

​	**一次 TCP 连接的大概需要消耗 3-4 个RTT，3 次握手 1.5 RTT，TLS 1-2RTT**, 如果 RTT 较长为100ms，那么仅仅建立时就需要 300ms，此时用户就会明显感觉到慢

## 3. TCP 协议僵化

​	由于网络中间设备和操作系统的历史原因，TCP 协议被大量使用，难以更新

## 4. QUIC 协议

​	同样的原因，发明一种独立于 TCP 和 UDP 协议之外的协议是难以做到的，于是 HTTP 3 选择了一个折衷的办法：**UDP协议**，基于 UDP 实现了类似于 TCP 的多路数据流，传输可靠性等功能，我们把这套功能称为 **QUIC 协议**

<img src="https://static001.geekbang.org/resource/image/0b/c6/0bae470bb49747b9a59f9f4bb496a9c6.png" alt="HTTP2 与 HTTP3 的协议栈比较" style="zoom: 67%;" />

通过上图可以看出，HTTP 3 的 QUIC 协议集合了以下几点功能

1. 实现了类似于 TCP 的流量控制、传输可靠性的功能。
   虽然 UDP 本身不提供传输的可靠性，但 QUIC 在 UDP 的基础上增加一层来保证数据的可靠性传输。
   包括数据包重传、拥塞控制以及一些只在 TCP 存在的特性
2. 集成了 TLS 加密功能，QUIC 的使用的是 TLS 1.3 。相较于早期版本的 TLS 1.3 做了优化，比如减少了握手所需的 RTT
3. 实现了 HTTP 2 的多路复用功能
   和 TCP 不同，QUIC 实现了在同一物理连接上可以有多个独立的逻辑数据流（如下图）。实现了数据流的单独传输，就解决了 TCP 中队头阻塞的问题。
4. 实现了快速握手功能，UDP 可以在 0-1 RTT 完成连接

<img src="https://static001.geekbang.org/resource/image/05/9a/05cc5720989aec75730ee4cb7e7c149a.png" style="zoom:67%;" />

## HTTP 3 的挑战

1. 服务器和浏览器支持度还不够
2. 系统内核对 UDP 的优化远远不如 TCP
3. 中间设备僵化的问题，这些设备对 UDP 的优化少于 TCP，在使用 QUIC 协议时，丢包率高达3%-7%